Guten Tag,

(mein Name ist Lars Kroll und),

# Zur Person

Für diejenigen von Ihnen, die mich nicht kennen, ich bin Medizinsoziologe mit einem methodischen Schwerpunkt und seit 2004 mit dem RKI, der Abteilung 2 und ihrer früheren Leitung verbunden. Bitte entschuldigen Sie darum, wenn ich im folgenden noch "wir" sage und das Monitoring meine.

Seit 2019 leite ich im Zi die Abteilung Data Science und Versorgungsanalysen. 

Wir entwickeln wir Machine Learning Ansätze im Bereich der Analyse von Abrechnungsdaten und Texten und stellen Informationssysteme für die Ausgestaltung der Versorgung bereit. Ebenfalls beraten wir die Träger in KI Projekten und zu statistischen Fragen und bringen Abrechnungsdaten in viele Innovationsfonds-Projekte ein.

# Überschrift Lehren aus der Pandemie

Seit Februar 2020 ist mein Team der zentrale Anlaufpunkt für Informationen zur Pandemie im KV-System und auch auf uns hat man dabei nicht immer gehört. Was sind nun meine Lehren im Hinblick auf die Digitalisierung des Monitorings?

# Lehren aus der Pandemie

Infrastruktur, Flexibilität, Schnelligkeit und Open Data.

*Infrastruktur*: Wir brauchten eine historisch einmalige Pandemie, um mit dem  *Intensivregister* eine Infrastruktur aufzubauen, die uns Einblicke in die Situation der Intensivmedizinischen Versorgung  verschafft. Diesen Weg müssen wir darum dringend weitergehen und noch mehr tagesaktuelle Daten zum Zustand unserer kritischen medizinischen Infrastruktur bekommen. Hier helfen jüngsten Gesetzesinitiativen des BMG perspektivisch.

*Flexibilität*: Die Pandemie hat gezeigt, wie wichtig *Surveys* sind, um *flexibel* auf Lagen zu reagieren. Sie können sehr kurzfristig Informationslücken schließen. Hier sind die Antikörperstudien des RKI ein eindrückliches Beispiel. Sie zeigen auch den Wert von Kooperationsnetzwerken mit anderen datenerhebenden Institution, wie DIW und DJI. Man kann aber auch aus anderen Studien lernen: Die COSMO-Studie zeigt den Wert von Echtzeitdaten, die problematische Heinsberg Studie den Wert von Schnelligkeit. 

Beide zuletzt genannten Studien machen auf Schwächen des heutigen Monitorings aufmerksam: So haben wir noch kein RKI Access-Panel, dass Daten wie respondi.com, die Anbieter hinter den COSMO-Daten, liefern kann. Die statistisch-/methodische Dokumentation der Studie ist entsprechend dürftig und zeigt, dass man manche Dinge lieber selber machen sollte. Unser Ansatz, Untersuchungen mit großem Aufwand und eigener Logistik vor Ort durchzuführen, ist auch nicht immer zielführend. Die bestehende Infrastruktur von Niedergelassenen oder Kliniken vor Ort zu nutzen, kann hier eine Alternative sein. Darum bietet es sich m.E. an, mit dem Hauzsärzteverband, dem BVKJ und dem Marburger Bund ins Gespräch kommen, um diese in Zukunft als Partner zu gewinnen. 

*Open Data*: Wir sehen uns als Forscher einer neuen Öffentlichkeit gegenüber, die anspruchsvoller geworden ist. Darum sollte sich das Monitoring möglichst eng mit der neuen *Projektgruppe Wissenschaftskommunikation* vernetzen. Für die Leitmedien wird dagegen Data Journalismus wichtiger. Fehlerfrei maschinenlesbare Datenformate müssen dafür in verlässlicher Form werden. Das leisten wir bisher nicht hinreichend.

Zuletzt *Apps*: Bei Projekte wie der CWA oder der Schulcloud hat man gesehen, dass Prototypen leicht, Produktion aber schwer ist. Wir brauchen interne Kompetenz in der Erstellung und im Verständnis von modernen Apps. Heutzutage sollte ein Public Health Institut jedenfalls nicht auf ArcGIS angewiesen sein, um ein Dashboard zu erstellen. Wir sollten moderne Frontend- und Backendtechnologien selbst hinreichend beherrschen. Diese Entwicklungskompetenz würde uns in vielen Projekten helfen. Ein Full Stack Data Scientist sollte heute Javascript, Python, SQL und R beherrschen. Sind wir hier auf dem richtigem Weg? 

# Modellierungen helfen Public Health

Das hier ist so eine Javascript Web-App. Hier geht es mir aber nicht um die digitale Technologie, sondern um die Potenziale ihrer Nutzung für Public Health. Wir konnten mit dieser App im Februar viele Entscheider*innen davon überzeugen, dass schnellstmöglich in den Praxen geimpft werden muss. Warum? Ich glaube auch, sie damit selbst prüfen konnten, ob Ihre Mittel und Ziele kongruent sind. Für solche Simulationen benötigen wir hinreichend konkrete Forschung, die Datengrundlagen dafür liefert aber auch interne Entwicklungskompetenzen. Ein weiter Grund ist zudem der Einzug von Apps ins SGB V. Wobei hier die Verordnungen noch sehr selten sind.

*klick*

Konzeptpapiere, Schaubilder, Diagramme und Tabellen sind dagegen eine notwendige aber keine hinreichende Bedingung um gehört zu werden.  

# Ziele

Was ergeben sich daraus für Ziele für das Monitoring?

*klick*

Was Monitoring ausmacht, hat Bärbel Kurth bereits 2009 prägnant formuliert. Es soll flexibel und adaptierter sein und jederzeit mit relevanten Daten bereitstehen. Genau das denke ich auch.

*klick*

**Grace Murray Hopper**

Sind wir heute da? Das Monitoring wurde für seine Verdienste um Public Health mit der Salomon Neumann Medaille ausgezeichnet. Das zukünftige digitale Monitoring muss den Anspruch haben, ebenso preiswürdig zu werden. Dabei gibt es kein "Business as usual"!

# Entwicklungsaufgaben

Für mich ist ein **agiles Gesundheitsmonitoring** der Weg, um dieses Ziel zu erreichen. Wir sollten mehr von Problemlösungsansätzen lernen, die anderen geholfen haben, komplexe Probleme mit Kreativität und Engagement zu lösen.
Um agiler im Sinne des Manifestes zu werden, müssen wir uns alle unsere Prozesse ansehen und auch die Art unserer Zusammenarbeit. Bei jedem Prozess müssen wir uns fragen: 

"Dient das was wir hier grade machen dazu, dass unser Kernprodukt, **Evidenz für Public Health**, schneller und besser für Politik, Wissenschaft und Bevölkerung bereitsteht? Müssen wir vielleicht eine Extrameile gehen, weil wir so nicht nur einen Auftrag erfüllen, sondern die Chance zu nutzen auch selbst besser werden?"

# Umsetzung

Wie kommen wir an dieses Ziel? Ich würde sagen die Abteilung braucht eine neue Strategie die "Data" und "Science" enger zusammenführt. Sie können Einwänden: "Hey, beides machen wir doch jeden Tag!" Stimmt, aber es passiert zu oft in getrennten Bereichen und ist zu wenig aufeinander bezogen und koordiniert. Probleme werden in temporären Arbeitsgruppen diskutiert statt von Projektteams mit klaren Ressourcen und klaren Meilensteinen gelöst zu werden. 

## Organisation

Das Monitoring hat Doppelstrukturen, Kompetenzen sind verstreut, anstatt organisatorisch gebündelt zu werden. So fällt wechselseitiges Lernen schwerer und ressourcensparender Standardisierung umso mehr. Ausgehend von einem Kompetenzzentrum könnten Profis in der Abteilung in agilen Teams Probleme lösen und die Kompetenz ihres Netzwerkes nutzen.  

## Infrastruktur

Die Abteilung ist groß, aber nicht so groß dass wir es uns leisten können, dass jeder Bereich sein eigenes Süppchen kocht. Softwareentwicklung, Datenaufbereitung, High Performance Analysen sowie Datengewinnungsprozesse können die gleichen Technologien nutzen. Das erleichtert wechselseitiges Lernen immens. Die Technologien sollten Open Source basiert sein, nicht nur um reproduzierbare Analysen zu ermöglichen, sondern weil wir unsere Mittel lieber in Menschen als in Lizenzen investieren sollten.

## Datenquellen

Das Gesundheitsmonitoring sollte mit jeder relevanten Datenquelle sicher umgehen können und diese sofern auch bei Bedarf mit den Surveys verknüpfen können. Hier muss nicht jeder Spezialist*in sein, aber es muss ein Kompetenzcluster dafür geben.

Die Surveys sind ein Baustein einer größeren Datenarchitektur. Sie sind und waren schon immer das zentrale Mittel um Datenlücken zu schließen, sei es weil bestehende Daten fehlen, nicht valide sind oder einen wichtigen Aspekt, wie beispielsweise sozial bedingte Ungleichheiten, außer acht lassen.

Überall da wo bereits Daten vorhanden sind müssen wir aber prüfen, ob ein Survey nötig ist oder ob wir uns gemeinsam mit dem BMG nicht einfach etwas mehr anstrengen müssen, um an diese Daten zu kommen. Das **FDZ für Gesundheitsdaten** am BfArM wird uns perspektivisch ungeahnte Möglichkeiten bieten. Gleichzeitig gibt es weitere Datenquellen für ein potenzielles Echtzeitmonitoring der Bevölkerung, die wir erschließen sollten.

Die Lücken werden also kleiner. Das kann uns nicht unbeeindruckt lassen. 

## Surveys

Wie Eingangs konstatiert: Wir brauchen klassische Stichproben mehr denn je. Wir müssen aber schneller werden und dabei verlässlicher und transparenter als kommerzielle Anbieter sein. Zudem brauchen wir flexible Tools die kurzfristig Fragen beantworten können. Hier wäre ein solides RKI Access Panel - gespeist aus Repräsentativen Stichproben - als weiterer Baustein optimal.

Zuletzt sollten wir bei unseren Surveydaten auch im Hinterkopf behalten, dass zunehmend Datensätze zur Evaluation von KI's benötigt werden. Mein Team hat für eine Demonstration innerhalb einer Woche als Demonstrator eine Melanom-Erkennung-KI mit einer Accuracy von 80% auf frei verfügbaren Bildern trainiert. Wie gut ist aber die Testgüte kommerzieller Ansätze in der wirklichen Bevölkerung etwa beim Einsatz in Screenings? Diese Frage könnten wir mit den Surveys untersuchen. 

## Surveyplanung und -prozesse

Um in Zukunft immer schneller immer mehr Evidenz zu liefern, müssen unsere Prozesse automatisiert und standardisiert werden. Das erfordert vielleicht manchmal Data Science Kompetenzen, die bisher noch nicht im Monitoring vorhanden sind. Die nötigen Tools gibt es aber umsonst und wir haben im RKI mit der Bioinformatik und nun auch mit dem ZKI-PH Kooperationspartner, die uns dabei helfen können. Da aber NLP im ZKI bisher keine Rolle zu spielen scheint, muss das Monitoring hier aber selbst investieren. Zumindest ist NLP die zentrale Technologie für Text Mining etwa bei der Sichtung von Social Media Trends oder bei Evidenzsuche in Publikationsdatenbanken. Ebenfalls ist NLP für KI mit medizinischen Abrechnungsdaten perfekt geeignet, wie wir schon untersuchen konnten.

Wir sollten auch nicht davor zurückschrecken uns mit universitären Parter*innen an neuen Technologieplattformen zu beteiligen. Der damit verbundene initiale Aufwand steht einer späteren Agilität gegenüber, wenn diese Tools einsatzfähig sind und mit geringem Aufwand modifiziert werden können. Außerdem ist jeder Impuls in solche Projekte ein zusätzlicher öffentlicher Nutzen des Monitorings.
 
## Publikationen 

Das Monitoring macht seit Jahren viele tolle Publikationen und hat auch in der Corona-Krise seine Schlagkraft in diesem Bereich gezeigt. 

Das Verhältnis von JOHM und externen Journals muss aber dabei stimmen, damit wir nicht zu selbstreferenziell werden. Für externe Journals gilt zudem, dass wir Preprints besser nutzen sollten, damit unsere Ergebnisse nicht zu spät sichtbar werden. Im Hinblick auf die Anforderungen der Top Journals müssen wir aber auch hier noch etwas zulegen. Hier ist Reproducability zentral. Ich mich etwa, was der letzte Artikel der Abteilung war, der bei Datenzugang voll reproduzierbar und bereits ohne Datenzugang hinreichend dokumentiert war?

Personenbezogene Gesundheitsdaten sind besonders schutzbedürftig, Datenschutz darf aber nicht zur Ausrede werden. Wir sollten den Anspruch haben, dass jede Publikation der Abteilung voll reproduzierbar ist. Das schliesst Daten, Quellcode und Tools ein. Fehler, die dabei von Anderen entdeckt werden, sollten nicht als ein individuelles Versagen interpretiert, sondern dankbar als Möglichkeit für Verbesserung angenommen werden. 

Es ist ein Privileg - aus Steuermitteln bezahlt - für dieses Public Health-Institut zu Forschen. Darum muss die Arbeit hier höchsten Standards genügen und möglichst umfassend zur Verfügung gestellt werden. Digitales Monitoring bedeutet für mich nicht: JoHM-PDFs statt GBE-Themenhefte oder Online- statt Papierfragebögen. Es bedeutet, dass wir die zur Verfügung stehenden digitalen Tools nutzen müssen, um unsere Zusammenarbeit und unsere Prozesse jeden Tag besser zu machen, um dem Ideal eines "agilen Gesundheitsmonitorings" näherzukommen. 

# Letzte Folie
 
Vielen Dank für Ihre Aufmerksamkeit. 